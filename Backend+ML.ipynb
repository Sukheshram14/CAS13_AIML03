{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq7kwx4wVDJJ"
      },
      "outputs": [],
      "source": [
        "!pip install flask pyngrok tweepy transformers pandas flask-cors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blRdtttNWFXM"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqCLydJFVqmX"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "from flask import Flask, request, jsonify\n",
        "import tweepy\n",
        "from transformers import pipeline\n",
        "from pyngrok import ngrok, conf\n",
        "from flask_cors import CORS\n",
        "from langdetect import detect\n",
        "import chardet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOPrGQcdUDhG"
      },
      "outputs": [],
      "source": [
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "conf.get_default().auth_token = userdata.get('NGROK')\n",
        "\n",
        "\n",
        "api_key = \"Your_API_Key\"\n",
        "api_key_secret = \"Your_API_Key_Secret\"\n",
        "access_token = \"Your_Access_token\"\n",
        "access_token_secret = \"Your_Access_token_secret\"\n",
        "bearer_token = \"Your_bearear_token\"\n",
        "\n",
        "client = tweepy.Client(\n",
        "    bearer_token=bearer_token,\n",
        "    consumer_key=api_key,\n",
        "    consumer_secret=api_key_secret,\n",
        "    access_token=access_token,\n",
        "    access_token_secret=access_token_secret\n",
        ")\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
        "emotion_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=False)\n",
        "\n",
        "def get_category(sentiment):\n",
        "    label = sentiment['label']\n",
        "    if label == \"negative\":\n",
        "        return \"negative\"\n",
        "    elif label == \"neutral\":\n",
        "        return \"neutral\"\n",
        "    else:\n",
        "        return \"positive\"\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/analyze_query', methods=['POST'])\n",
        "def analyze_query():\n",
        "    results = []\n",
        "    tweet_texts = []\n",
        "\n",
        "    data = request.get_json(silent=True)\n",
        "    user_query = data.get(\"query\", None) if data else request.values.get(\"query\")\n",
        "\n",
        "    if not user_query:\n",
        "        return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "    language = data.get(\"language\", \"en\") if data else \"en\"\n",
        "    query = f\"{user_query} -is:retweet lang:{language}\"\n",
        "\n",
        "    try:\n",
        "        response = client.search_recent_tweets(query=query, max_results=10)\n",
        "        tweets = response.data if response.data is not None else []\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": \"Error fetching tweets: \" + str(e)}), 500\n",
        "\n",
        "    if not tweets:\n",
        "        return jsonify({\"error\": \"No tweets found for the query\"}), 404\n",
        "\n",
        "    tweet_texts = [tweet.text for tweet in tweets]\n",
        "\n",
        "    for tweet_text in tweet_texts:\n",
        "        detected_lang = detect(tweet_text)\n",
        "        sentiment_result = sentiment_pipeline(tweet_text)[0]\n",
        "        category = get_category(sentiment_result)\n",
        "        emotion_result = emotion_pipeline(tweet_text)[0]\n",
        "\n",
        "        results.append({\n",
        "            \"Tweet\": tweet_text,\n",
        "            \"Detected Language\": detected_lang,\n",
        "            \"Sentiment\": category,\n",
        "            \"Emotion\": emotion_result['label'],\n",
        "            \"Emotion Score\": round(emotion_result['score'], 3)\n",
        "        })\n",
        "\n",
        "    return jsonify({\"results\": results})\n",
        "\n",
        "@app.route('/analyze_file', methods=['POST'])\n",
        "def analyze_file():\n",
        "    results = []\n",
        "    tweet_texts = []\n",
        "\n",
        "    file = request.files.get(\"file\", None)\n",
        "    if not file:\n",
        "        return jsonify({\"error\": \"No CSV file uploaded\"}), 400\n",
        "\n",
        "    try:\n",
        "        file_bytes = file.read()\n",
        "        detected_encoding = chardet.detect(file_bytes)[\"encoding\"]\n",
        "        df_csv = pd.read_csv(io.BytesIO(file_bytes), encoding=detected_encoding or \"utf-8\", encoding_errors=\"replace\")\n",
        "\n",
        "        tweet_texts = df_csv['Tweet'].tolist() if 'Tweet' in df_csv.columns else df_csv.iloc[:, 0].tolist()\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Failed to process CSV file: {str(e)}\"}), 500\n",
        "\n",
        "    for tweet_text in tweet_texts:\n",
        "        detected_lang = detect(tweet_text)\n",
        "        sentiment_result = sentiment_pipeline(tweet_text)[0]\n",
        "        category = get_category(sentiment_result)\n",
        "        emotion_result = emotion_pipeline(tweet_text)[0]\n",
        "\n",
        "        results.append({\n",
        "            \"Tweet\": tweet_text,\n",
        "            \"Detected Language\": detected_lang,\n",
        "            \"Sentiment\": category,\n",
        "            \"Emotion\": emotion_result['label'],\n",
        "            \"Emotion Score\": round(emotion_result['score'], 3)\n",
        "        })\n",
        "\n",
        "    return jsonify({\"results\": results})\n",
        "\n",
        "public_url = ngrok.connect(5000)\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:5000/\\\"\".format(public_url))\n",
        "\n",
        "app.run(port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JXsoUFqyhe2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
