{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIEA55cu07XR",
        "outputId": "e55c002b-8972-481d-f608-5aaf67e09b6a"
      },
      "outputs": [],
      "source": [
        "!pip install flask flask_cors tweepy transformers torch pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l37JSl1l3CN1",
        "outputId": "ebd2c8da-dc02-41b1-bdde-ae09240a7159"
      },
      "outputs": [],
      "source": [
        "!pip install flask flask-cors tweepy transformers torch pandas matplotlib pyngrok\n",
        "!ngrok config add-authtoken 2sJEuojAIXme0CuF7o0FH2DYhSK_2fBAphZTKf9uyXLWGvQRH\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Y9LWKPy09XT",
        "outputId": "41dd503c-1320-4c48-cf43-9f1203592b0f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Mar/2025 14:38:06] \"OPTIONS /analyze HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Only 9 tweet(s) were fetched. Expected minimum 10 tweets if available.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [06/Mar/2025 14:38:10] \"POST /analyze HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Mar/2025 14:40:41] \"OPTIONS /analyze HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [06/Mar/2025 14:40:42] \"\u001b[31m\u001b[1mPOST /analyze HTTP/1.1\u001b[0m\" 429 -\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline\n",
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "# Set pandas option to display full tweet text\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Twitter API credentials (use secure storage in production!)\n",
        "api_key = \"hjuola1OWKXvXAalYGOcFA3rA\"\n",
        "api_key_secret = \"NKdKURGjZsHmO6Woa0wyrhZC8w1qEhAl38lkypd7w8EFeaYBS5\"\n",
        "access_token = \"1897656288533999616-e1CbS66X9dJBbkyjzXhPcecluLIIkU\"\n",
        "access_token_secret = \"puTxOb8uRHt6Y6kEhfPRvpMqbaP5XvCkVaXBEybvTeB33\"\n",
        "bearer_token = \"AAAAAAAAAAAAAAAAAAAAACcLzwEAAAAATe7LZ%2F2VWSGLF3%2FzNujN%2FSNhqQU%3DUJo6eA3eqj9Ibyhc66h7icH6p1YHXNrdPSA3InhAMLI01yBc7r\"\n",
        "\n",
        "# Create a Tweepy client for API v2\n",
        "client = tweepy.Client(bearer_token=bearer_token,\n",
        "                       consumer_key=api_key,\n",
        "                       consumer_secret=api_key_secret,\n",
        "                       access_token=access_token,\n",
        "                       access_token_secret=access_token_secret)\n",
        "\n",
        "# Initialize the sentiment analysis pipeline\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "# Initialize the emotion detection pipeline\n",
        "emotion_pipeline = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=False)\n",
        "\n",
        "# Function to convert the model's star rating into a sentiment category\n",
        "def get_category(sentiment):\n",
        "    label = sentiment['label']  # e.g., \"5 stars\"\n",
        "    rating = int(label.split()[0])\n",
        "    if rating <= 2:\n",
        "        return \"negative\"\n",
        "    elif rating == 3:\n",
        "        return \"neutral\"\n",
        "    else:\n",
        "        return \"positive\"\n",
        "\n",
        "@app.route('/analyze', methods=['POST'])\n",
        "def analyze():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        user_query = data.get(\"query\", \"\")\n",
        "        if not user_query:\n",
        "            return jsonify({\"error\": \"No query provided\"}), 400\n",
        "\n",
        "        # Build the query string\n",
        "        query = f\"{user_query} -is:retweet lang:en\"\n",
        "\n",
        "        # Try to fetch recent tweets using Twitter API v2\n",
        "        try:\n",
        "            response = client.search_recent_tweets(query=query, max_results=10)\n",
        "            tweets = response.data if response.data is not None else []\n",
        "        except tweepy.TooManyRequests:\n",
        "            return jsonify({\"error\": \"Rate limit exceeded. Please wait and try again later.\"}), 429\n",
        "\n",
        "        if len(tweets) < 10:\n",
        "            print(f\"Warning: Only {len(tweets)} tweet(s) were fetched. Expected minimum 10 tweets if available.\")\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # Analyze sentiment and emotion for each fetched tweet\n",
        "        if tweets:\n",
        "            for tweet in tweets:\n",
        "                tweet_text = tweet.text\n",
        "                # Sentiment analysis\n",
        "                sentiment_result = sentiment_pipeline(tweet_text)[0]\n",
        "                label = sentiment_result['label']\n",
        "                rating = int(label.split()[0])\n",
        "                category = get_category(sentiment_result)\n",
        "                # Emotion detection\n",
        "                emotion_result = emotion_pipeline(tweet_text)[0]\n",
        "                emotion_label = emotion_result['label']\n",
        "                emotion_score = emotion_result['score']\n",
        "                results.append({\n",
        "                    \"Tweet\": tweet_text,\n",
        "                    \"Rating\": rating,\n",
        "                    \"Sentiment\": category,\n",
        "                    \"Emotion\": emotion_label,\n",
        "                    \"Emotion Score\": round(emotion_score, 3)\n",
        "                })\n",
        "\n",
        "            # Return results as JSON\n",
        "            return jsonify(results)\n",
        "\n",
        "        else:\n",
        "            return jsonify({\"error\": \"No tweets found for the query or rate limit exceeded.\"}), 404\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2P_7n-r1Bit",
        "outputId": "ee874430-4b67-4fd9-df92-f1c9ee6b2b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://e798-34-74-175-116.ngrok-free.app\" -> \"http://localhost:5000\">"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "ngrok.connect(5000)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
